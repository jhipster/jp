#!/usr/bin/env python3
"""
JHipsteræ—¥æœ¬èªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè‡ªå‹•ç¿»è¨³ã‚·ã‚¹ãƒ†ãƒ 
ã‚³ãƒŸãƒƒãƒˆ&PRä½œæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import argparse
import json
import os
import subprocess
import sys
from datetime import datetime
from typing import Optional, Dict, List
import google.generativeai as genai


class CommitAndPRManager:
    def __init__(self, dry_run: bool = False):
        self.dry_run = dry_run
        self.bot_user = os.getenv("BOT_GIT_USER", "jhipster-auto-translation-bot")
        self.bot_email = os.getenv("BOT_GIT_EMAIL", "bot@jhipster.tech")
        
        # Gemini APIåˆæœŸåŒ–
        api_key = os.getenv("GEMINI_API_KEY")
        if api_key and api_key != "fake_api_key_for_development":
            genai.configure(api_key=api_key)
            self.model = genai.GenerativeModel("gemini-1.5-flash")
        else:
            self.model = None
    
    def setup_git_config(self) -> bool:
        """Gitè¨­å®šã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        try:
            if not self.dry_run:
                subprocess.run(
                    ["git", "config", "user.name", self.bot_user],
                    check=True
                )
                subprocess.run(
                    ["git", "config", "user.email", self.bot_email],
                    check=True
                )
            
            print(f"âœ… Git config set: {self.bot_user} <{self.bot_email}>")
            return True
            
        except subprocess.CalledProcessError as e:
            print(f"âŒ Error setting up git config: {e}")
            return False
    
    def get_current_branch(self) -> Optional[str]:
        """ç¾åœ¨ã®ãƒ–ãƒ©ãƒ³ãƒåã‚’å–å¾—"""
        try:
            result = subprocess.run(
                ["git", "branch", "--show-current"],
                capture_output=True, text=True, check=True
            )
            return result.stdout.strip()
        except subprocess.CalledProcessError:
            return None
    
    def get_commit_hash_from_branch(self, branch_name: str) -> Optional[str]:
        """ãƒ–ãƒ©ãƒ³ãƒåã‹ã‚‰ã‚³ãƒŸãƒƒãƒˆãƒãƒƒã‚·ãƒ¥ã‚’æŠ½å‡º"""
        if branch_name and branch_name.startswith("sync-"):
            return branch_name[5:]  # "sync-"ã‚’é™¤å»
        return None
    
    def analyze_translation_quality_with_llm(self, upstream_content: str, translated_content: str, file_path: str) -> Dict:
        """LLMã‚’ä½¿ã£ã¦ç¿»è¨³å“è³ªã‚’åˆ†æ"""
        if not self.model:
            return {"has_issues": False, "analysis": "LLM not available"}
        
        prompt = f"""ä»¥ä¸‹ã®è‹±èªæ–‡æ›¸ã¨ãã®æ—¥æœ¬èªç¿»è¨³ã‚’æ¯”è¼ƒã—ã€ç¿»è¨³ã®å“è³ªå•é¡Œã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚

**ç¿»è¨³å‰ï¼ˆè‹±èªåŸæ–‡ï¼‰:**
```
{upstream_content}
```

**ç¿»è¨³å¾Œï¼ˆæ—¥æœ¬èªç‰ˆï¼‰:**
```
{translated_content}
```

**åˆ†æé …ç›®:**
1. é‡è¦ãªæƒ…å ±ã®æ¬ è½ï¼ˆimportæ–‡ã€ç”»åƒã€ãƒªãƒ³ã‚¯ã€ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãªã©ï¼‰
2. æ§‹é€ çš„ãªå¤‰æ›´ï¼ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã€æ®µè½ã®å‰Šé™¤ãƒ»è¿½åŠ ï¼‰
3. ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³è¨˜æ³•ã®å•é¡Œ
4. æ„å›³ã—ãªã„å†…å®¹ã®é‡è¤‡
5. ç¿»è¨³ã®ä¸€è²«æ€§

**å‡ºåŠ›å½¢å¼ï¼ˆJSONï¼‰:**
```json
{{
  "has_issues": true/false,
  "issues": [
    {{
      "type": "missing_content|structural_change|markdown_issue|duplication|inconsistency",
      "severity": "high|medium|low",
      "description": "å…·ä½“çš„ãªå•é¡Œã®èª¬æ˜",
      "location": "å•é¡Œã®ã‚ã‚‹ç®‡æ‰€ï¼ˆå¯èƒ½ãªå ´åˆï¼‰"
    }}
  ],
  "summary": "åˆ†æçµæœã®è¦ç´„"
}}
```

JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"""
        
        try:
            response = self.model.generate_content(prompt)
            if response.text:
                # JSONã®æŠ½å‡ºã‚’è©¦è¡Œ
                response_text = response.text.strip()
                if response_text.startswith("```json"):
                    response_text = response_text[7:-3].strip()
                elif response_text.startswith("```"):
                    response_text = response_text[3:-3].strip()
                
                analysis = json.loads(response_text)
                return analysis
            else:
                return {"has_issues": False, "analysis": "No response from LLM"}
                
        except Exception as e:
            print(f"âš ï¸ Error in LLM analysis for {file_path}: {e}")
            return {"has_issues": False, "analysis": f"Analysis failed: {e}"}
    
    def check_line_count_differences(self, commit_hash: str, classification_file: Optional[str] = None, threshold: int = 1) -> List[Dict]:
        """è¡Œæ•°å·®ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å·®ãŒã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿”ã™"""
        files_with_line_differences = []
        
        # åˆ†é¡ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç¿»è¨³å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
        files_to_check = []
        if classification_file and os.path.exists(classification_file):
            try:
                with open(classification_file, 'r', encoding='utf-8') as f:
                    classification = json.load(f)
                
                # ç¿»è¨³å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆa, b-1, b-2ï¼‰ã‚’åé›†
                summary = classification.get("summary", {})
                files_to_check.extend(summary.get("a", []))
                files_to_check.extend(summary.get("b-1", []))
                files_to_check.extend(summary.get("b-2", []))
                
            except Exception as e:
                print(f"âš ï¸ Error reading classification file for line count check: {e}")
                return files_with_line_differences
        
        # å„ãƒ•ã‚¡ã‚¤ãƒ«ã®è¡Œæ•°ã‚’ãƒã‚§ãƒƒã‚¯
        for file_path in files_to_check:
            try:
                # ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã¨è¡Œæ•°
                if not os.path.exists(file_path):
                    continue
                    
                with open(file_path, 'r', encoding='utf-8') as f:
                    current_content = f.read()
                    current_lines = len(current_content.split('\n'))
                
                # ä¸Šæµã‚³ãƒŸãƒƒãƒˆã§ã®ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã¨è¡Œæ•°
                try:
                    result = subprocess.run(
                        ["git", "show", f"{commit_hash}:{file_path}"],
                        capture_output=True, text=True, check=True
                    )
                    upstream_content = result.stdout
                    upstream_lines = len(upstream_content.split('\n'))
                    
                    # è¡Œæ•°ã®å·®ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆ1è¡Œã§ã‚‚å·®ãŒã‚ã‚Œã°æ¤œå‡ºï¼‰
                    line_diff = abs(current_lines - upstream_lines)
                    if line_diff >= threshold:
                        diff_ratio = (line_diff / upstream_lines * 100) if upstream_lines > 0 else 0
                        files_with_line_differences.append({
                            "file": file_path,
                            "upstream_lines": upstream_lines,
                            "current_lines": current_lines,
                            "line_diff": line_diff,
                            "diff_ratio": round(diff_ratio, 1),
                            "upstream_content": upstream_content,
                            "current_content": current_content
                        })
                        print(f"ğŸ“ Line count difference detected in {file_path}: {upstream_lines} â†’ {current_lines} (å·®:{line_diff}è¡Œ)")
                    
                except subprocess.CalledProcessError:
                    # ä¸Šæµã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
                    continue
                    
            except Exception as e:
                print(f"âš ï¸ Error checking line count for {file_path}: {e}")
                continue
        
        return files_with_line_differences
    
    def check_translation_quality(self, commit_hash: str, classification_file: Optional[str] = None) -> Dict[str, List[Dict]]:
        """è¡Œæ•°å·®ãŒã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿LLMã§ç¿»è¨³å“è³ªã‚’åˆ†æ"""
        results = {"files_with_issues": [], "analysis_summary": [], "line_count_differences": []}
        
        # 1. ã¾ãšè¡Œæ•°å·®ã‚’ãƒã‚§ãƒƒã‚¯
        files_with_line_differences = self.check_line_count_differences(commit_hash, classification_file)
        results["line_count_differences"] = files_with_line_differences
        
        if not files_with_line_differences:
            print("âœ… No significant line count differences detected")
            return results
        
        if not self.model:
            print("âš ï¸ LLM not available for detailed analysis of files with line differences")
            return results
        
        print(f"ğŸ” Found {len(files_with_line_differences)} files with line count differences, analyzing with LLM...")
        
        # 2. è¡Œæ•°å·®ãŒã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿LLMã§è©³ç´°åˆ†æ
        for file_info in files_with_line_differences:
            file_path = file_info["file"]
            upstream_content = file_info["upstream_content"]
            current_content = file_info["current_content"]
            
            try:
                print(f"ğŸ¤– LLM analyzing {file_path}...")
                analysis = self.analyze_translation_quality_with_llm(
                    upstream_content, current_content, file_path
                )
                
                # è¡Œæ•°æƒ…å ±ã‚’åˆ†æçµæœã«è¿½åŠ 
                analysis["line_info"] = {
                    "upstream_lines": file_info["upstream_lines"],
                    "current_lines": file_info["current_lines"],
                    "line_diff": file_info["line_diff"],
                    "diff_ratio": file_info["diff_ratio"]
                }
                
                if analysis.get("has_issues", False):
                    results["files_with_issues"].append({
                        "file": file_path,
                        "analysis": analysis
                    })
                
                results["analysis_summary"].append({
                    "file": file_path,
                    "has_issues": analysis.get("has_issues", False),
                    "summary": analysis.get("summary", "No summary available"),
                    "line_info": analysis["line_info"]
                })
                
            except Exception as e:
                print(f"âš ï¸ Error in LLM analysis for {file_path}: {e}")
                # LLMåˆ†æã«å¤±æ•—ã—ãŸå ´åˆã§ã‚‚è¡Œæ•°æƒ…å ±ã¯è¨˜éŒ²
                results["analysis_summary"].append({
                    "file": file_path,
                    "has_issues": True,
                    "summary": f"LLM analysis failed: {e}",
                    "line_info": {
                        "upstream_lines": file_info["upstream_lines"],
                        "current_lines": file_info["current_lines"],
                        "line_diff": file_info["line_diff"],
                        "diff_ratio": file_info["diff_ratio"]
                    }
                })
        
        return results
    
    def check_changes_exist(self) -> bool:
        """å¤‰æ›´ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆã‚³ãƒŸãƒƒãƒˆå‰ã®ç¢ºèªç”¨ï¼‰"""
        try:
            # å¤‰æ›´ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªï¼ˆã‚¹ãƒ†ãƒ¼ã‚¸ã•ã‚Œã¦ã„ãªã„å¤‰æ›´ã‚‚å«ã‚€ï¼‰
            result = subprocess.run(
                ["git", "diff", "--name-only", "HEAD"],
                capture_output=True, text=True, check=True
            )
            
            changed_files = [f for f in result.stdout.strip().split('\n') if f]
            
            if changed_files:
                print(f"ğŸ“‹ Found {len(changed_files)} changed files")
                for file in changed_files[:10]:  # æœ€åˆã®10ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿è¡¨ç¤º
                    print(f"   - {file}")
                if len(changed_files) > 10:
                    print(f"   ... and {len(changed_files) - 10} more files")
                return True
            else:
                print("ğŸ“‹ No changes detected")
                return False
                
        except subprocess.CalledProcessError as e:
            print(f"âŒ Error checking changes: {e}")
            return False
    
    def create_commit(self, commit_hash: str) -> bool:
        """ç¿»è¨³æ¸ˆã¿å¤‰æ›´ã‚’ã‚³ãƒŸãƒƒãƒˆï¼ˆäºŒæ¬¡ã‚³ãƒŸãƒƒãƒˆï¼‰"""
        commit_message = f"docs(sync): upstream {commit_hash} ç¿»è¨³\n\nğŸ¤– Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>"
        
        try:
            if not self.dry_run:
                # ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ï¼ˆç¿»è¨³æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å«ã‚€å…¨å¤‰æ›´ï¼‰
                subprocess.run(["git", "add", "-A"], check=True)
                
                # äºŒæ¬¡ã‚³ãƒŸãƒƒãƒˆ
                subprocess.run(
                    ["git", "commit", "-m", commit_message],
                    check=True
                )
            else:
                print("DRY RUN: Would stage and commit with message:")
                print(f"   git add -A")
                print(f"   git commit -m \"{commit_message}\"")
            
            print(f"âœ… Created translation commit: docs(sync): upstream {commit_hash} ç¿»è¨³")
            return True
            
        except subprocess.CalledProcessError as e:
            print(f"âŒ Error creating translation commit: {e}")
            return False
    
    def check_conflict_markers_in_changed_files(self) -> List[str]:
        """syncãƒ–ãƒ©ãƒ³ãƒã§å¤‰æ›´ã•ã‚ŒãŸç¿»è¨³å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã§ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆãƒãƒ¼ã‚«ãƒ¼ã®å­˜åœ¨ã‚’ãƒã‚§ãƒƒã‚¯"""
        files_with_conflicts = []
        
        try:
            # git diff --name-onlyã§å¤‰æ›´ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
            result = subprocess.run(
                ["git", "diff", "--name-only", "origin/main..HEAD"],
                capture_output=True, text=True, check=True
            )
            
            changed_files = [f for f in result.stdout.strip().split('\n') if f]
            
            for file_path in changed_files:
                if not file_path or not os.path.exists(file_path):
                    continue
                
                # ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã® '.' ã§å§‹ã¾ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ãƒ•ã‚©ãƒ«ãƒ€ã‚’é™¤å¤–ï¼ˆç¿»è¨³å¯¾è±¡å¤–ï¼‰
                if file_path.startswith('.'):
                    continue
                
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                        if any(marker in content for marker in ['<<<<<<<', '=======', '>>>>>>>']):
                            files_with_conflicts.append(file_path)
                except Exception:
                    # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–
                    continue
            
        except subprocess.CalledProcessError as e:
            print(f"âš ï¸ Error checking conflict markers: {e}")
        
        return files_with_conflicts

    def generate_pr_body(self, classification_file: Optional[str] = None, commit_hash: Optional[str] = None) -> str:
        """PRæœ¬æ–‡ã‚’ç”Ÿæˆ"""
        body_parts = []
        
        body_parts.append("## ğŸ”„ UpstreamåŒæœŸã¨ç¿»è¨³")
        body_parts.append("")
        body_parts.append("ã“ã®PRã¯ã€JHipster upstream ãƒªãƒã‚¸ãƒˆãƒªã‹ã‚‰ã®å¤‰æ›´ã‚’è‡ªå‹•çš„ã«ç¿»è¨³ã—ãŸã‚‚ã®ã§ã™ã€‚")
        body_parts.append("")
        
        # ã‚³ãƒŸãƒƒãƒˆãƒãƒƒã‚·ãƒ¥æƒ…å ±ã‚’è¿½åŠ 
        if commit_hash:
            body_parts.append("### ğŸ“ ç¿»è¨³å…ƒæƒ…å ±")
            body_parts.append("")
            body_parts.append(f"- **Upstream commit**: [{commit_hash}](https://github.com/jhipster/jhipster.github.io/commit/{commit_hash})")
            body_parts.append("")
            
            # ç¿»è¨³å“è³ªåˆ†æã‚’å®Ÿè¡Œï¼ˆè¡Œæ•°å·®ãƒã‚§ãƒƒã‚¯ â†’ LLMåˆ†æï¼‰
            quality_results = self.check_translation_quality(commit_hash, classification_file)
            
            if quality_results["line_count_differences"]:
                body_parts.append("### ğŸ“ è¡Œæ•°å·®ç•°æ¤œå‡ºçµæœ")
                body_parts.append("")
                body_parts.append("ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ä¸Šæµç‰ˆã¨è¡Œæ•°å·®ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸï¼š")
                body_parts.append("")
                
                for line_diff in quality_results["line_count_differences"]:
                    body_parts.append(f"- `{line_diff['file']}`: {line_diff['upstream_lines']}è¡Œ â†’ {line_diff['current_lines']}è¡Œ (å·®:{line_diff['line_diff']}è¡Œ)")
                body_parts.append("")
                
                if quality_results["files_with_issues"]:
                    body_parts.append("### ğŸ¤– LLMè©³ç´°åˆ†æçµæœ")
                    body_parts.append("")
                    body_parts.append("è¡Œæ•°å·®ç•°ãŒæ¤œå‡ºã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®LLMåˆ†æçµæœï¼š")
                    body_parts.append("")
                    
                    for file_result in quality_results["files_with_issues"]:
                        file_path = file_result["file"]
                        analysis = file_result["analysis"]
                        line_info = analysis.get("line_info", {})
                        
                        body_parts.append(f"#### ğŸ“„ `{file_path}`")
                        body_parts.append("")
                        body_parts.append(f"**è¡Œæ•°**: {line_info.get('upstream_lines', 'N/A')}è¡Œ â†’ {line_info.get('current_lines', 'N/A')}è¡Œ (å·®:{line_info.get('line_diff', 'N/A')}è¡Œ)")
                        body_parts.append(f"**LLMåˆ†æ**: {analysis.get('summary', 'N/A')}")
                        body_parts.append("")
                        
                        issues = analysis.get("issues", [])
                        if issues:
                            body_parts.append("**æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ:**")
                            for issue in issues:
                                severity_emoji = {"high": "ğŸš¨", "medium": "âš ï¸", "low": "â„¹ï¸"}.get(issue.get("severity", "low"), "â„¹ï¸")
                                body_parts.append(f"- {severity_emoji} **{issue.get('type', 'unknown')}**: {issue.get('description', 'N/A')}")
                                if issue.get('location'):
                                    body_parts.append(f"  - ç®‡æ‰€: {issue['location']}")
                            body_parts.append("")
                    
                    body_parts.append("**ğŸ” æ‰‹å‹•ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚**")
                    body_parts.append("")
                    
                elif quality_results["analysis_summary"]:
                    body_parts.append("### âœ… LLMåˆ†æçµæœ")
                    body_parts.append("")
                    body_parts.append("è¡Œæ•°å·®ç•°ãŒã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’LLMåˆ†æã—ã¾ã—ãŸãŒã€é‡å¤§ãªå•é¡Œã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼š")
                    body_parts.append("")
                    
                    for summary in quality_results["analysis_summary"]:
                        line_info = summary.get("line_info", {})
                        body_parts.append(f"- âœ… `{summary['file']}` ({line_info.get('upstream_lines', 'N/A')} â†’ {line_info.get('current_lines', 'N/A')}è¡Œ, å·®:{line_info.get('line_diff', 'N/A')}è¡Œ): {summary['summary']}")
                    body_parts.append("")
                else:
                    body_parts.append("âš ï¸ è¡Œæ•°å·®ç•°ãƒ•ã‚¡ã‚¤ãƒ«ã®LLMåˆ†æãŒã§ãã¾ã›ã‚“ã§ã—ãŸï¼ˆLLMæœªåˆ©ç”¨ï¼‰ã€‚æ‰‹å‹•ç¢ºèªã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
                    body_parts.append("")
                    
            else:
                body_parts.append("### âœ… ç¿»è¨³å“è³ªãƒã‚§ãƒƒã‚¯çµæœ")
                body_parts.append("")
                body_parts.append("è¡Œæ•°ãƒã‚§ãƒƒã‚¯ã§å¤§å¹…ãªå·®ç•°ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ç¿»è¨³å“è³ªã«å•é¡Œã¯ãªã„ã¨åˆ¤æ–­ã•ã‚Œã¾ã™ã€‚")
                body_parts.append("")
        
        # åˆ†é¡æƒ…å ±ã‚’å«ã‚ã‚‹
        if classification_file and os.path.exists(classification_file):
            try:
                with open(classification_file, 'r', encoding='utf-8') as f:
                    classification = json.load(f)
                
                body_parts.append("### ğŸ“‹ å¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«æ¦‚è¦")
                body_parts.append("")
                body_parts.append(f"- **ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°**: {classification['total_files']}")
                body_parts.append(f"- **ç¿»è¨³å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°**: {classification['translatable_files']}")
                body_parts.append("")
                
                summary = classification["summary"]
                if summary["a"]:
                    body_parts.append(f"#### ğŸ†• æ–°è¦æ–‡æ›¸ ({len(summary['a'])} files)")
                    for file in summary["a"][:5]:
                        body_parts.append(f"- `{file}`")
                    if len(summary["a"]) > 5:
                        body_parts.append(f"- ... and {len(summary['a']) - 5} more files")
                    body_parts.append("")
                
                if summary["b-1"]:
                    body_parts.append(f"#### âœï¸ æ›´æ–°æ–‡æ›¸ - è¡çªãªã— ({len(summary['b-1'])} files)")
                    for file in summary["b-1"][:5]:
                        body_parts.append(f"- `{file}`")
                    if len(summary["b-1"]) > 5:
                        body_parts.append(f"- ... and {len(summary['b-1']) - 5} more files")
                    body_parts.append("")
                
                if summary["b-2"]:
                    body_parts.append(f"#### âš ï¸ æ›´æ–°æ–‡æ›¸ - è¡çªã‚ã‚Š ({len(summary['b-2'])} files)")
                    body_parts.append("")
                    body_parts.append("âš ï¸ ã“ã‚Œã‚‰ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ç¿»è¨³è¡çªãŒå«ã¾ã‚Œã¦ã„ã¾ã—ãŸã€‚æ‰‹å‹•ç¢ºèªãŒæ¨å¥¨ã•ã‚Œã¾ã™ã€‚")
                    body_parts.append("")
                    for file in summary["b-2"][:5]:
                        body_parts.append(f"- `{file}`")
                    if len(summary["b-2"]) > 5:
                        body_parts.append(f"- ... and {len(summary['b-2']) - 5} more files")
                    body_parts.append("")
                
                if summary["c"]:
                    body_parts.append(f"#### ğŸ“„ éç¿»è¨³ãƒ•ã‚¡ã‚¤ãƒ« ({len(summary['c'])} files)")
                    body_parts.append("ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ç¿»è¨³å¯¾è±¡å¤–ã®ãŸã‚ã€ãã®ã¾ã¾ã‚³ãƒ”ãƒ¼ã•ã‚Œã¾ã—ãŸã€‚")
                    body_parts.append("")
                    for file in summary["c"][:5]:
                        body_parts.append(f"- `{file}`")
                    if len(summary["c"]) > 5:
                        body_parts.append(f"- ... and {len(summary['c']) - 5} more files")
                    body_parts.append("")
                        
            except Exception as e:
                print(f"âš ï¸ Error reading classification file: {e}")
        
        # ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆãƒãƒ¼ã‚«ãƒ¼ãƒã‚§ãƒƒã‚¯
        files_with_conflicts = self.check_conflict_markers_in_changed_files()
        if files_with_conflicts:
            body_parts.append("### âš ï¸ ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆãƒãƒ¼ã‚«ãƒ¼æ¤œå‡º")
            body_parts.append("")
            body_parts.append("ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆãƒãƒ¼ã‚«ãƒ¼ãŒæ®‹ã£ã¦ã„ã¾ã™ï¼š")
            body_parts.append("")
            for conflict_file in files_with_conflicts:
                body_parts.append(f"- âš ï¸ `{conflict_file}` - ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆãƒãƒ¼ã‚«ãƒ¼ãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
            body_parts.append("")
            body_parts.append("**ğŸš¨ ã“ã‚Œã‚‰ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯æ‰‹å‹•ã§ä¿®æ­£ãŒå¿…è¦ã§ã™ã€‚**")
            body_parts.append("")
        
        body_parts.append("### ğŸ” ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ãŠé¡˜ã„")
        body_parts.append("")
        body_parts.append("- ç¿»è¨³ã®å“è³ªã¨æ­£ç¢ºæ€§ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        body_parts.append("- æŠ€è¡“ç”¨èªã®ç¿»è¨³ãŒé©åˆ‡ã‹ãƒã‚§ãƒƒã‚¯ã—ã¦ãã ã•ã„")
        body_parts.append("- ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ãŒæ­£ã—ãä¿æŒã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„")
        body_parts.append("- è¡çªã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ«ã¯ç‰¹ã«æ³¨æ„æ·±ãç¢ºèªã—ã¦ãã ã•ã„")
        body_parts.append("")
        body_parts.append("---")
        body_parts.append("")
        body_parts.append("ğŸ¤– Generated with [Claude Code](https://claude.ai/code)")
        
        return '\n'.join(body_parts)
    
    def get_base_branch(self, branch_name: str) -> str:
        """ãƒ–ãƒ©ãƒ³ãƒã®æ´¾ç”Ÿå…ƒã‚’æ¤œå‡ºã—ã¦ãƒ™ãƒ¼ã‚¹ãƒ–ãƒ©ãƒ³ãƒã‚’æ±ºå®š"""
        try:
            # å€™è£œãƒ–ãƒ©ãƒ³ãƒãƒªã‚¹ãƒˆï¼ˆå„ªå…ˆé †ä½é †ï¼‰
            candidate_branches = ["main", "auto-translation"]
            
            best_base = "main"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            best_distance = float('inf')
            
            for candidate in candidate_branches:
                try:
                    # ç¾åœ¨ã®ãƒ–ãƒ©ãƒ³ãƒã¨å€™è£œãƒ–ãƒ©ãƒ³ãƒã®å…±é€šç¥–å…ˆã‚’å–å¾—
                    result = subprocess.run(
                        ["git", "merge-base", "HEAD", candidate],
                        capture_output=True, text=True, check=True
                    )
                    merge_base = result.stdout.strip()
                    
                    # å…±é€šç¥–å…ˆã‹ã‚‰ç¾åœ¨ã®ãƒ–ãƒ©ãƒ³ãƒã¾ã§ã®ã‚³ãƒŸãƒƒãƒˆæ•°ã‚’å–å¾—
                    result = subprocess.run(
                        ["git", "rev-list", "--count", f"{merge_base}..HEAD"],
                        capture_output=True, text=True, check=True
                    )
                    distance = int(result.stdout.strip())
                    
                    # ã‚ˆã‚Šè¿‘ã„ç¥–å…ˆã‚’æŒã¤ãƒ–ãƒ©ãƒ³ãƒã‚’é¸æŠ
                    if distance < best_distance:
                        best_distance = distance
                        best_base = candidate
                        
                except subprocess.CalledProcessError:
                    # ãƒ–ãƒ©ãƒ³ãƒãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ç„¡è¦–
                    continue
            
            print(f"ğŸ“ Detected base branch: {best_base} (distance: {best_distance} commits)")
            return best_base
            
        except Exception as e:
            print(f"âš ï¸ Error detecting base branch: {e}, using default 'main'")
            return "main"

    def create_pull_request(self, branch_name: str, commit_hash: str, classification_file: Optional[str] = None) -> bool:
        """ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ä½œæˆ"""
        pr_title = f"docs: upstream {commit_hash} Translation"
        pr_body = self.generate_pr_body(classification_file, commit_hash)
        
        # ãƒ™ãƒ¼ã‚¹ãƒ–ãƒ©ãƒ³ãƒã‚’è‡ªå‹•æ¤œå‡º
        base_branch = self.get_base_branch(branch_name)
        
        # ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³æ™‚ã¯å¸¸ã«PRæœ¬æ–‡ã‚’æ¨™æº–å‡ºåŠ›
        if self.dry_run:
            print("=" * 80)
            print("DRY RUN: PRæœ¬æ–‡ï¼ˆMarkdownå½¢å¼ï¼‰")
            print("=" * 80)
            print()
            print(f"# {pr_title}")
            print(f"Base branch: {base_branch}")
            print()
            print(pr_body)
            print()
            print("=" * 80)
            return True
        
        try:
            # ã¾ãšãƒ–ãƒ©ãƒ³ãƒã‚’ãƒ—ãƒƒã‚·ãƒ¥
            subprocess.run(
                ["git", "push", "-u", "origin", branch_name],
                check=True
            )
            
            # PRã‚’ä½œæˆ
            subprocess.run([
                "gh", "pr", "create",
                "--title", pr_title,
                "--body", pr_body,
                "--head", branch_name,
                "--base", base_branch
            ], check=True)
            
            print(f"âœ… Created pull request: {pr_title} (base: {base_branch})")
            return True
            
        except subprocess.CalledProcessError as e:
            print(f"âŒ Error creating pull request: {e}")
            return False
    
    def push_to_origin(self, branch_name: str) -> bool:
        """originã«ãƒ—ãƒƒã‚·ãƒ¥"""
        try:
            if not self.dry_run:
                subprocess.run(
                    ["git", "push", "-u", "origin", branch_name],
                    check=True
                )
            else:
                print(f"DRY RUN: Would push branch {branch_name} to origin")
            
            print(f"âœ… Pushed branch to origin: {branch_name}")
            return True
            
        except subprocess.CalledProcessError as e:
            print(f"âŒ Error pushing to origin: {e}")
            return False


def main():
    parser = argparse.ArgumentParser(description="Commit changes and create PR")
    parser.add_argument(
        "--classification",
        help="Classification JSON file for PR body generation"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Dry run mode (don't actually commit/push/create PR)"
    )
    parser.add_argument(
        "--push-origin",
        type=str,
        choices=["true", "false"],
        default="true",
        help="Whether to push to origin"
    )
    parser.add_argument(
        "--create-pr",
        type=str,
        choices=["true", "false"],
        default="true",
        help="Whether to create pull request"
    )
    
    args = parser.parse_args()
    
    # DRY_RUNç’°å¢ƒå¤‰æ•°ã‚‚ãƒã‚§ãƒƒã‚¯
    dry_run = args.dry_run or os.getenv("DRY_RUN", "false").lower() == "true"
    push_origin = args.push_origin.lower() == "true"
    create_pr = args.create_pr.lower() == "true"
    
    manager = CommitAndPRManager(dry_run)
    
    # Gitè¨­å®šã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    if not manager.setup_git_config():
        sys.exit(1)
    
    # ç¾åœ¨ã®ãƒ–ãƒ©ãƒ³ãƒã‚’å–å¾—
    branch_name = manager.get_current_branch()
    if not branch_name:
        print("âŒ Could not determine current branch")
        sys.exit(1)
    
    print(f"ğŸ“‹ Current branch: {branch_name}")
    
    # ãƒ–ãƒ©ãƒ³ãƒåã‹ã‚‰ã‚³ãƒŸãƒƒãƒˆãƒãƒƒã‚·ãƒ¥ã‚’æŠ½å‡º
    commit_hash = manager.get_commit_hash_from_branch(branch_name)
    if not commit_hash:
        print("âš ï¸ Could not extract commit hash from branch name, using timestamp")
        commit_hash = datetime.now().strftime("%Y%m%d")
    
    # å¤‰æ›´ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    has_changes = manager.check_changes_exist()
    
    # å¤‰æ›´ãŒãªã„å ´åˆ
    if not has_changes:
        print("ğŸ“‹ No changes to commit")
        # ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³æ™‚ã¯PRæœ¬æ–‡ç”Ÿæˆã®ã¿å®Ÿè¡Œ
        if dry_run and create_pr:
            manager.create_pull_request(branch_name, commit_hash, args.classification)
            print("âœ… Dry run completed")
        sys.exit(0)
    
    # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ï¼šã‚³ãƒŸãƒƒãƒˆã‚’ä½œæˆ
    if not dry_run:
        if not manager.create_commit(commit_hash):
            sys.exit(1)
    else:
        print(f"DRY RUN: Would create commit with message: docs(sync): upstream {commit_hash} ç¿»è¨³")
    
    # originã«ãƒ—ãƒƒã‚·ãƒ¥
    if push_origin and not dry_run:
        if not manager.push_to_origin(branch_name):
            sys.exit(1)
    elif push_origin and dry_run:
        print(f"DRY RUN: Would push branch {branch_name} to origin")
    
    # ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ä½œæˆ
    if create_pr:
        if not manager.create_pull_request(branch_name, commit_hash, args.classification):
            if not dry_run:  # ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³æ™‚ã¯ã‚¨ãƒ©ãƒ¼çµ‚äº†ã—ãªã„
                sys.exit(1)
    
    completion_msg = "âœ… Dry run completed" if dry_run else "âœ… All operations completed successfully"
    print(completion_msg)


if __name__ == "__main__":
    main()