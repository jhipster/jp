#!/usr/bin/env python3
"""
JHipsteræ—¥æœ¬èªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè‡ªå‹•ç¿»è¨³ã‚·ã‚¹ãƒ†ãƒ 
Geminiç¿»è¨³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import argparse
import json
import os
import re
import sys
import time
from pathlib import Path
from typing import List, Optional, Tuple

import google.generativeai as genai


class GeminiTranslator:
    def __init__(self, api_key: str, model_name: str = "gemini-1.5-flash"):
        self.api_key = api_key
        self.model_name = model_name
        self.max_tokens = 4096
        self.style_guide_content = ""
        
        # Gemini APIã‚’è¨­å®š
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel(model_name)
        
        # ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ã‚’èª­ã¿è¾¼ã¿
        self.load_style_guide()
    
    def load_style_guide(self):
        """ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ã‚’èª­ã¿è¾¼ã¿"""
        # å®Ÿè¡Œä½ç½®ã«é–¢ä¿‚ãªãã€æ­£ã—ã„ãƒ‘ã‚¹ã‚’æ¢ç´¢
        possible_paths = [
            Path("docs/style-guide.md"),
            Path(".github/auto-translation/docs/style-guide.md"),
            Path("../docs/style-guide.md"),
            Path("../../docs/style-guide.md")
        ]
        
        style_guide_path = None
        for path in possible_paths:
            if path.exists():
                style_guide_path = path
                break
        if style_guide_path and style_guide_path.exists():
            try:
                with open(style_guide_path, 'r', encoding='utf-8') as f:
                    self.style_guide_content = f.read()
                print(f"âœ… Loaded style guide: {style_guide_path}")
            except Exception as e:
                print(f"âš ï¸ Error loading style guide: {e}")
        else:
            print(f"âš ï¸ Style guide not found in any of the expected locations")
    
    def count_tokens_estimate(self, text: str) -> int:
        """ãƒ†ã‚­ã‚¹ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ¦‚ç®—"""
        # ç°¡æ˜“çš„ãªè¨ˆç®—ï¼šæ—¥æœ¬èªã¯1æ–‡å­—=1.5ãƒˆãƒ¼ã‚¯ãƒ³ã€è‹±èªã¯1å˜èª=1ãƒˆãƒ¼ã‚¯ãƒ³
        japanese_chars = len(re.findall(r'[ã²ã‚‰ãŒãªã‚«ã‚¿ã‚«ãƒŠæ¼¢å­—]', text))
        english_words = len(re.findall(r'\b[a-zA-Z]+\b', text))
        other_chars = len(text) - japanese_chars - english_words
        
        return int(japanese_chars * 1.5 + english_words + other_chars * 0.3)
    
    def split_content_by_paragraphs(self, content: str) -> List[str]:
        """å†…å®¹ã‚’æ®µè½å˜ä½ã§åˆ†å‰²"""
        # ç©ºè¡Œã§åˆ†å‰²
        paragraphs = re.split(r'\n\s*\n', content)
        
        chunks = []
        current_chunk = ""
        
        for paragraph in paragraphs:
            paragraph = paragraph.strip()
            if not paragraph:
                continue
            
            # ç¾åœ¨ã®ãƒãƒ£ãƒ³ã‚¯ã«æ®µè½ã‚’è¿½åŠ ã—ãŸå ´åˆã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨ˆç®—
            test_chunk = f"{current_chunk}\n\n{paragraph}".strip()
            if self.count_tokens_estimate(test_chunk) > self.max_tokens and current_chunk:
                # ç¾åœ¨ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ä¿å­˜ã—ã€æ–°ã—ã„ãƒãƒ£ãƒ³ã‚¯ã‚’é–‹å§‹
                chunks.append(current_chunk)
                current_chunk = paragraph
            else:
                current_chunk = test_chunk
        
        # æœ€å¾Œã®ãƒãƒ£ãƒ³ã‚¯ã‚’è¿½åŠ 
        if current_chunk:
            chunks.append(current_chunk)
        
        return chunks
    
    def create_translation_prompt(self, content: str) -> str:
        """ç¿»è¨³ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ"""
        style_guide_section = ""
        if self.style_guide_content:
            style_guide_section = f"""
ä»¥ä¸‹ã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ã«å¾“ã£ã¦ç¿»è¨³ã—ã¦ãã ã•ã„ï¼š

{self.style_guide_content}

---

"""
        
        prompt = f"""{style_guide_section}ä»¥ä¸‹ã®è‹±èªã®JHipsterãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ—¥æœ¬èªã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚

é‡è¦ãªæ³¨æ„äº‹é …ï¼š
1. ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã‚’ä¿æŒã—ã¦ãã ã•ã„
2. ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã€URLã€ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€ã‚³ãƒãƒ³ãƒ‰ã¯ç¿»è¨³ã—ãªã„ã§ãã ã•ã„
3. æŠ€è¡“ç”¨èªã¯é©åˆ‡ãªæ—¥æœ¬èªã«ç¿»è¨³ã™ã‚‹ã‹ã€å¿…è¦ã«å¿œã˜ã¦è‹±èªã®ã¾ã¾æ®‹ã—ã¦ãã ã•ã„
4. æ–‡ä½“ã¯å¸¸ä½“ï¼ˆã§ã‚ã‚‹èª¿ï¼‰ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„
5. å…ƒã®æ–‡æ›¸ã®æ§‹é€ ã¨æ”¹è¡Œã‚’ä¿æŒã—ã¦ãã ã•ã„
6. HTMLã‚¿ã‚°ã‚„ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³è¨˜æ³•ã¯å¤‰æ›´ã—ãªã„ã§ãã ã•ã„

ç¿»è¨³å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆï¼š

{content}

ç¿»è¨³çµæœï¼ˆæ—¥æœ¬èªã®ã¿ï¼‰ï¼š"""
        
        return prompt
    
    def translate_chunk(self, content: str, retry_count: int = 3) -> Optional[str]:
        """å˜ä¸€ãƒãƒ£ãƒ³ã‚¯ã‚’ç¿»è¨³"""
        prompt = self.create_translation_prompt(content)
        
        for attempt in range(retry_count):
            try:
                response = self.model.generate_content(prompt)
                
                if response.text:
                    translated = response.text.strip()
                    
                    # è¡Œæ•°ãƒã‚§ãƒƒã‚¯
                    original_lines = len(content.split('\n'))
                    translated_lines = len(translated.split('\n'))
                    
                    # è¡Œæ•°ã®å·®ãŒ20%ã‚’è¶…ãˆã‚‹å ´åˆã¯è­¦å‘Š
                    if abs(original_lines - translated_lines) / max(original_lines, 1) > 0.2:
                        print(f"âš ï¸ Line count mismatch: {original_lines} -> {translated_lines}")
                    
                    return translated
                else:
                    print(f"âš ï¸ Empty response from Gemini (attempt {attempt + 1})")
                    
            except Exception as e:
                print(f"âš ï¸ Translation error (attempt {attempt + 1}): {e}")
                if attempt < retry_count - 1:
                    time.sleep(2 ** attempt)  # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
        
        return None
    
    def translate_file(self, file_path: str, output_path: Optional[str] = None) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“ã‚’ç¿»è¨³"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            print(f"ğŸ“ Translating: {file_path}")
            
            # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’åˆ†å‰²
            chunks = self.split_content_by_paragraphs(content)
            print(f"   Split into {len(chunks)} chunks")
            
            translated_chunks = []
            for i, chunk in enumerate(chunks):
                print(f"   Translating chunk {i + 1}/{len(chunks)}...")
                translated_chunk = self.translate_chunk(chunk)
                
                if translated_chunk is None:
                    print(f"âŒ Failed to translate chunk {i + 1}")
                    return False
                
                translated_chunks.append(translated_chunk)
                
                # APIåˆ¶é™ã‚’é¿ã‘ã‚‹ãŸã‚ã®å¾…æ©Ÿ
                if i < len(chunks) - 1:
                    time.sleep(1)
            
            # ç¿»è¨³çµæœã‚’çµåˆ
            translated_content = '\n\n'.join(translated_chunks)
            
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æ±ºå®š
            if output_path is None:
                output_path = file_path
            
            # ç¿»è¨³çµæœã‚’ä¿å­˜
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(translated_content)
            
            print(f"âœ… Translation completed: {output_path}")
            return True
            
        except Exception as e:
            print(f"âŒ Error translating file {file_path}: {e}")
            return False
    
    def translate_files_from_classification(self, classification_file: str, mode: str = "all") -> bool:
        """åˆ†é¡çµæœã‹ã‚‰ç¿»è¨³å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¿»è¨³"""
        try:
            with open(classification_file, 'r', encoding='utf-8') as f:
                classification = json.load(f)
            
            files_to_translate = []
            
            if mode == "all":
                # a, b-1, b-2ã®ã™ã¹ã¦ã‚’ç¿»è¨³
                files_to_translate.extend(classification["summary"]["a"])
                files_to_translate.extend(classification["summary"]["b-1"])
                files_to_translate.extend(classification["summary"]["b-2"])
            elif mode == "selective":
                # aã¨b-1ã®ã¿ã‚’ç¿»è¨³ï¼ˆè¡çªãŒã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã¯é™¤å¤–ï¼‰
                files_to_translate.extend(classification["summary"]["a"])
                files_to_translate.extend(classification["summary"]["b-1"])
            elif mode == "new-only":
                # æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’ç¿»è¨³
                files_to_translate.extend(classification["summary"]["a"])
            
            if not files_to_translate:
                print("ğŸ“‹ No files to translate")
                return True
            
            print(f"ğŸ“‹ Found {len(files_to_translate)} files to translate")
            
            success_count = 0
            for file_path in files_to_translate:
                if self.translate_file(file_path):
                    success_count += 1
                else:
                    print(f"âŒ Failed to translate: {file_path}")
            
            print(f"âœ… Translation completed: {success_count}/{len(files_to_translate)} files")
            return success_count == len(files_to_translate)
            
        except Exception as e:
            print(f"âŒ Error in batch translation: {e}")
            return False


def main():
    parser = argparse.ArgumentParser(description="Translate files using Gemini API")
    parser.add_argument(
        "--file",
        help="Single file to translate"
    )
    parser.add_argument(
        "--classification",
        help="Classification JSON file for batch translation"
    )
    parser.add_argument(
        "--mode",
        choices=["all", "selective", "new-only"],
        default="selective",
        help="Translation mode for batch processing"
    )
    parser.add_argument(
        "--output",
        help="Output file path (for single file translation)"
    )
    
    args = parser.parse_args()
    
    # API ã‚­ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key or api_key == "fake_api_key_for_development":
        print("âŒ GEMINI_API_KEY environment variable is required")
        sys.exit(1)
    
    translator = GeminiTranslator(api_key)
    
    if args.file:
        # å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ç¿»è¨³
        success = translator.translate_file(args.file, args.output)
        sys.exit(0 if success else 1)
    elif args.classification:
        # ãƒãƒƒãƒç¿»è¨³
        success = translator.translate_files_from_classification(args.classification, args.mode)
        sys.exit(0 if success else 1)
    else:
        print("âŒ Either --file or --classification must be specified")
        sys.exit(1)


if __name__ == "__main__":
    main()